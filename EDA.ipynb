{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "## Music Genre Classification Dataset\n",
        "\n",
        "This notebook provides a comprehensive exploratory data analysis of the music genre classification dataset, including:\n",
        "- **Dataset Overview**: File counts, languages, genres\n",
        "- **Metadata Analysis**: Language/genre distributions, lyrics analysis\n",
        "- **Audio File Analysis**: Sample rates, durations, file properties\n",
        "- **Feature Analysis**: Mel-spectrograms, audio features, lyrics embeddings\n",
        "- **Visualizations**: Distributions, correlations, sample spectrograms\n",
        "- **Data Quality Checks**: Missing values, duplicates, outliers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from scipy.io import wavfile\n",
        "from collections import Counter\n",
        "import pickle\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Configuration\n",
        "BANGLA_DATASET_DIR = r'E:\\425 Project\\Datasets\\Bangla_Datasets'\n",
        "ENGLISH_DATASET_DIR = r'E:\\425 Project\\Datasets\\English_Datasets'\n",
        "METADATA_FILE = r'E:\\425 Project\\Datasets\\updated_metadata.csv'\n",
        "RESULTS_DIR = r'E:\\425 Project\\results'\n",
        "\n",
        "# Create results directory if it doesn't exist\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")\n",
        "print(f\"üìÅ Results will be saved to: {RESULTS_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Dataset Overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load metadata\n",
        "print(\"Loading metadata...\")\n",
        "metadata_df = pd.read_csv(METADATA_FILE)\n",
        "print(f\"‚úÖ Metadata loaded: {len(metadata_df)} entries\")\n",
        "print(f\"\\nMetadata columns: {list(metadata_df.columns)}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(metadata_df.head())\n",
        "\n",
        "# Get dataset structure\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DATASET STRUCTURE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Bangla dataset\n",
        "bangla_genres = [d for d in os.listdir(BANGLA_DATASET_DIR) \n",
        "                 if os.path.isdir(os.path.join(BANGLA_DATASET_DIR, d))]\n",
        "bangla_genres.sort()\n",
        "\n",
        "bangla_file_counts = {}\n",
        "for genre in bangla_genres:\n",
        "    genre_path = os.path.join(BANGLA_DATASET_DIR, genre)\n",
        "    files = [f for f in os.listdir(genre_path) if f.endswith('.wav')]\n",
        "    bangla_file_counts[genre] = len(files)\n",
        "\n",
        "# English dataset\n",
        "english_genres = [d for d in os.listdir(ENGLISH_DATASET_DIR) \n",
        "                  if os.path.isdir(os.path.join(ENGLISH_DATASET_DIR, d))]\n",
        "english_genres.sort()\n",
        "\n",
        "english_file_counts = {}\n",
        "for genre in english_genres:\n",
        "    genre_path = os.path.join(ENGLISH_DATASET_DIR, genre)\n",
        "    files = [f for f in os.listdir(genre_path) if f.endswith('.wav')]\n",
        "    english_file_counts[genre] = len(files)\n",
        "\n",
        "print(f\"\\nüìä BANGLA DATASET:\")\n",
        "print(f\"   Total genres: {len(bangla_genres)}\")\n",
        "print(f\"   Genres: {', '.join(bangla_genres)}\")\n",
        "print(f\"   Total files: {sum(bangla_file_counts.values())}\")\n",
        "for genre, count in sorted(bangla_file_counts.items()):\n",
        "    print(f\"   - {genre}: {count} files\")\n",
        "\n",
        "print(f\"\\nüìä ENGLISH DATASET:\")\n",
        "print(f\"   Total genres: {len(english_genres)}\")\n",
        "print(f\"   Genres: {', '.join(english_genres)}\")\n",
        "print(f\"   Total files: {sum(english_file_counts.values())}\")\n",
        "for genre, count in sorted(english_file_counts.items()):\n",
        "    print(f\"   - {genre}: {count} files\")\n",
        "\n",
        "print(f\"\\nüìä OVERALL SUMMARY:\")\n",
        "total_files = sum(bangla_file_counts.values()) + sum(english_file_counts.values())\n",
        "total_genres = len(set(bangla_genres) | set(english_genres))\n",
        "print(f\"   Total audio files: {total_files}\")\n",
        "print(f\"   Total unique genres: {total_genres}\")\n",
        "print(f\"   Languages: Bangla (bn), English (en)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Metadata Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic metadata statistics\n",
        "print(\"=\"*60)\n",
        "print(\"METADATA STATISTICS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nüìã Dataset Info:\")\n",
        "print(f\"   Total entries: {len(metadata_df)}\")\n",
        "print(f\"   Columns: {list(metadata_df.columns)}\")\n",
        "print(f\"\\nüìã Data Types:\")\n",
        "print(metadata_df.dtypes)\n",
        "print(f\"\\nüìã Missing Values:\")\n",
        "print(metadata_df.isnull().sum())\n",
        "print(f\"\\nüìã Basic Statistics:\")\n",
        "print(metadata_df.describe(include='all'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Language distribution\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"LANGUAGE DISTRIBUTION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "language_counts = metadata_df['language'].value_counts()\n",
        "print(\"\\nLanguage counts:\")\n",
        "for lang, count in language_counts.items():\n",
        "    percentage = (count / len(metadata_df)) * 100\n",
        "    print(f\"   {lang}: {count} ({percentage:.2f}%)\")\n",
        "\n",
        "# Visualize language distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Pie chart\n",
        "axes[0].pie(language_counts.values, labels=language_counts.index, autopct='%1.1f%%', \n",
        "            startangle=90, colors=sns.color_palette(\"husl\", len(language_counts)))\n",
        "axes[0].set_title('Language Distribution (Pie Chart)', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Bar chart\n",
        "axes[1].bar(language_counts.index, language_counts.values, color=sns.color_palette(\"husl\", len(language_counts)))\n",
        "axes[1].set_title('Language Distribution (Bar Chart)', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Language', fontsize=12)\n",
        "axes[1].set_ylabel('Count', fontsize=12)\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "for i, v in enumerate(language_counts.values):\n",
        "    axes[1].text(i, v + 10, str(v), ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(RESULTS_DIR, 'language_distribution.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n‚úÖ Language distribution plot saved!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Genre distribution\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"GENRE DISTRIBUTION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "genre_counts = metadata_df['genre'].value_counts()\n",
        "print(\"\\nGenre counts:\")\n",
        "for genre, count in genre_counts.items():\n",
        "    percentage = (count / len(metadata_df)) * 100\n",
        "    print(f\"   {genre}: {count} ({percentage:.2f}%)\")\n",
        "\n",
        "# Visualize genre distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Horizontal bar chart\n",
        "axes[0].barh(genre_counts.index, genre_counts.values, color=sns.color_palette(\"husl\", len(genre_counts)))\n",
        "axes[0].set_title('Genre Distribution (Bar Chart)', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Count', fontsize=12)\n",
        "axes[0].set_ylabel('Genre', fontsize=12)\n",
        "axes[0].grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Add count labels\n",
        "for i, v in enumerate(genre_counts.values):\n",
        "    axes[0].text(v + 5, i, str(v), va='center', fontweight='bold')\n",
        "\n",
        "# Pie chart (top 10 genres)\n",
        "top_genres = genre_counts.head(10)\n",
        "axes[1].pie(top_genres.values, labels=top_genres.index, autopct='%1.1f%%', \n",
        "            startangle=90, colors=sns.color_palette(\"husl\", len(top_genres)))\n",
        "axes[1].set_title('Top 10 Genres Distribution', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(RESULTS_DIR, 'genre_distribution.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n‚úÖ Genre distribution plot saved!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Genre by Language\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"GENRE BY LANGUAGE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "genre_language = pd.crosstab(metadata_df['genre'], metadata_df['language'])\n",
        "print(\"\\nGenre-Language Cross-tabulation:\")\n",
        "print(genre_language)\n",
        "\n",
        "# Visualize\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "sns.heatmap(genre_language, annot=True, fmt='d', cmap='YlOrRd', ax=ax, \n",
        "            cbar_kws={'label': 'Count'})\n",
        "ax.set_title('Genre Distribution by Language (Heatmap)', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Language', fontsize=12)\n",
        "ax.set_ylabel('Genre', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(RESULTS_DIR, 'genre_language_heatmap.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n‚úÖ Genre-Language heatmap saved!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Lyrics Analysis (Bangla Dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lyrics statistics\n",
        "print(\"=\"*60)\n",
        "print(\"LYRICS ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Filter Bangla entries\n",
        "bangla_metadata = metadata_df[metadata_df['language'] == 'bn'].copy()\n",
        "\n",
        "# Calculate lyrics statistics\n",
        "bangla_metadata['lyrics_length'] = bangla_metadata['lyrics'].fillna('').str.len()\n",
        "bangla_metadata['lyrics_word_count'] = bangla_metadata['lyrics'].fillna('').str.split().str.len()\n",
        "bangla_metadata['has_lyrics'] = bangla_metadata['lyrics'].fillna('').str.len() > 0\n",
        "\n",
        "print(f\"\\nüìù Lyrics Statistics:\")\n",
        "print(f\"   Total Bangla entries: {len(bangla_metadata)}\")\n",
        "print(f\"   Entries with lyrics: {bangla_metadata['has_lyrics'].sum()}\")\n",
        "print(f\"   Entries without lyrics: {(~bangla_metadata['has_lyrics']).sum()}\")\n",
        "\n",
        "print(f\"\\nüìù Lyrics Length Statistics:\")\n",
        "print(bangla_metadata['lyrics_length'].describe())\n",
        "\n",
        "print(f\"\\nüìù Word Count Statistics:\")\n",
        "print(bangla_metadata['lyrics_word_count'].describe())\n",
        "\n",
        "# Visualize lyrics statistics\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Lyrics length distribution\n",
        "axes[0, 0].hist(bangla_metadata['lyrics_length'], bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "axes[0, 0].set_title('Distribution of Lyrics Length (Characters)', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Character Count', fontsize=10)\n",
        "axes[0, 0].set_ylabel('Frequency', fontsize=10)\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# Word count distribution\n",
        "axes[0, 1].hist(bangla_metadata['lyrics_word_count'], bins=50, color='lightcoral', edgecolor='black', alpha=0.7)\n",
        "axes[0, 1].set_title('Distribution of Word Count', fontsize=12, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Word Count', fontsize=10)\n",
        "axes[0, 1].set_ylabel('Frequency', fontsize=10)\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# Lyrics length by genre (boxplot)\n",
        "if len(bangla_metadata['genre'].unique()) > 1:\n",
        "    genre_order = bangla_metadata.groupby('genre')['lyrics_length'].median().sort_values(ascending=False).index\n",
        "    sns.boxplot(data=bangla_metadata, x='genre', y='lyrics_length', order=genre_order, ax=axes[1, 0])\n",
        "    axes[1, 0].set_title('Lyrics Length by Genre', fontsize=12, fontweight='bold')\n",
        "    axes[1, 0].set_xlabel('Genre', fontsize=10)\n",
        "    axes[1, 0].set_ylabel('Character Count', fontsize=10)\n",
        "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "    axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "# Word count by genre (boxplot)\n",
        "if len(bangla_metadata['genre'].unique()) > 1:\n",
        "    sns.boxplot(data=bangla_metadata, x='genre', y='lyrics_word_count', order=genre_order, ax=axes[1, 1])\n",
        "    axes[1, 1].set_title('Word Count by Genre', fontsize=12, fontweight='bold')\n",
        "    axes[1, 1].set_xlabel('Genre', fontsize=10)\n",
        "    axes[1, 1].set_ylabel('Word Count', fontsize=10)\n",
        "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "    axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(RESULTS_DIR, 'lyrics_analysis.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n‚úÖ Lyrics analysis plots saved!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Audio File Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze audio file properties\n",
        "print(\"=\"*60)\n",
        "print(\"AUDIO FILE ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Sample a subset of files for analysis (to avoid long processing time)\n",
        "sample_size = 100  # Analyze 100 files from each dataset\n",
        "audio_properties = []\n",
        "\n",
        "print(f\"\\nüìä Analyzing audio file properties (sampling {sample_size} files per dataset)...\")\n",
        "\n",
        "# Bangla dataset\n",
        "bangla_files_analyzed = 0\n",
        "for genre in bangla_genres[:3]:  # Sample first 3 genres\n",
        "    if bangla_files_analyzed >= sample_size:\n",
        "        break\n",
        "    genre_path = os.path.join(BANGLA_DATASET_DIR, genre)\n",
        "    files = [f for f in os.listdir(genre_path) if f.endswith('.wav')][:sample_size//3]\n",
        "    \n",
        "    for file in files:\n",
        "        if bangla_files_analyzed >= sample_size:\n",
        "            break\n",
        "        file_path = os.path.join(genre_path, file)\n",
        "        try:\n",
        "            sr, audio = wavfile.read(file_path)\n",
        "            duration = len(audio) / sr\n",
        "            file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB\n",
        "            \n",
        "            # Check if stereo or mono\n",
        "            channels = 1 if len(audio.shape) == 1 else audio.shape[1]\n",
        "            \n",
        "            audio_properties.append({\n",
        "                'file': file,\n",
        "                'language': 'bn',\n",
        "                'genre': genre,\n",
        "                'sample_rate': sr,\n",
        "                'duration': duration,\n",
        "                'file_size_mb': file_size,\n",
        "                'channels': channels,\n",
        "                'samples': len(audio) if channels == 1 else audio.shape[0]\n",
        "            })\n",
        "            bangla_files_analyzed += 1\n",
        "        except Exception as e:\n",
        "            print(f\"   Error reading {file_path}: {e}\")\n",
        "\n",
        "# English dataset\n",
        "english_files_analyzed = 0\n",
        "for genre in english_genres[:3]:  # Sample first 3 genres\n",
        "    if english_files_analyzed >= sample_size:\n",
        "        break\n",
        "    genre_path = os.path.join(ENGLISH_DATASET_DIR, genre)\n",
        "    files = [f for f in os.listdir(genre_path) if f.endswith('.wav')][:sample_size//3]\n",
        "    \n",
        "    for file in files:\n",
        "        if english_files_analyzed >= sample_size:\n",
        "            break\n",
        "        file_path = os.path.join(genre_path, file)\n",
        "        try:\n",
        "            sr, audio = wavfile.read(file_path)\n",
        "            duration = len(audio) / sr\n",
        "            file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB\n",
        "            \n",
        "            channels = 1 if len(audio.shape) == 1 else audio.shape[1]\n",
        "            \n",
        "            audio_properties.append({\n",
        "                'file': file,\n",
        "                'language': 'en',\n",
        "                'genre': genre,\n",
        "                'sample_rate': sr,\n",
        "                'duration': duration,\n",
        "                'file_size_mb': file_size,\n",
        "                'channels': channels,\n",
        "                'samples': len(audio) if channels == 1 else audio.shape[0]\n",
        "            })\n",
        "            english_files_analyzed += 1\n",
        "        except Exception as e:\n",
        "            print(f\"   Error reading {file_path}: {e}\")\n",
        "\n",
        "audio_df = pd.DataFrame(audio_properties)\n",
        "print(f\"\\n‚úÖ Analyzed {len(audio_df)} audio files\")\n",
        "print(f\"\\nüìä Audio Properties Summary:\")\n",
        "print(audio_df.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize audio properties\n",
        "if len(audio_df) > 0:\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
        "    \n",
        "    # Sample rate distribution\n",
        "    axes[0, 0].hist(audio_df['sample_rate'], bins=20, color='steelblue', edgecolor='black', alpha=0.7)\n",
        "    axes[0, 0].set_title('Sample Rate Distribution', fontsize=12, fontweight='bold')\n",
        "    axes[0, 0].set_xlabel('Sample Rate (Hz)', fontsize=10)\n",
        "    axes[0, 0].set_ylabel('Frequency', fontsize=10)\n",
        "    axes[0, 0].grid(alpha=0.3)\n",
        "    \n",
        "    # Duration distribution\n",
        "    axes[0, 1].hist(audio_df['duration'], bins=30, color='coral', edgecolor='black', alpha=0.7)\n",
        "    axes[0, 1].set_title('Duration Distribution', fontsize=12, fontweight='bold')\n",
        "    axes[0, 1].set_xlabel('Duration (seconds)', fontsize=10)\n",
        "    axes[0, 1].set_ylabel('Frequency', fontsize=10)\n",
        "    axes[0, 1].grid(alpha=0.3)\n",
        "    \n",
        "    # File size distribution\n",
        "    axes[0, 2].hist(audio_df['file_size_mb'], bins=30, color='mediumseagreen', edgecolor='black', alpha=0.7)\n",
        "    axes[0, 2].set_title('File Size Distribution', fontsize=12, fontweight='bold')\n",
        "    axes[0, 2].set_xlabel('File Size (MB)', fontsize=10)\n",
        "    axes[0, 2].set_ylabel('Frequency', fontsize=10)\n",
        "    axes[0, 2].grid(alpha=0.3)\n",
        "    \n",
        "    # Sample rate by language\n",
        "    sns.boxplot(data=audio_df, x='language', y='sample_rate', ax=axes[1, 0])\n",
        "    axes[1, 0].set_title('Sample Rate by Language', fontsize=12, fontweight='bold')\n",
        "    axes[1, 0].set_xlabel('Language', fontsize=10)\n",
        "    axes[1, 0].set_ylabel('Sample Rate (Hz)', fontsize=10)\n",
        "    axes[1, 0].grid(alpha=0.3)\n",
        "    \n",
        "    # Duration by language\n",
        "    sns.boxplot(data=audio_df, x='language', y='duration', ax=axes[1, 1])\n",
        "    axes[1, 1].set_title('Duration by Language', fontsize=12, fontweight='bold')\n",
        "    axes[1, 1].set_xlabel('Language', fontsize=10)\n",
        "    axes[1, 1].set_ylabel('Duration (seconds)', fontsize=10)\n",
        "    axes[1, 1].grid(alpha=0.3)\n",
        "    \n",
        "    # Channels distribution\n",
        "    channel_counts = audio_df['channels'].value_counts()\n",
        "    axes[1, 2].bar(channel_counts.index.astype(str), channel_counts.values, \n",
        "                    color='plum', edgecolor='black', alpha=0.7)\n",
        "    axes[1, 2].set_title('Audio Channels Distribution', fontsize=12, fontweight='bold')\n",
        "    axes[1, 2].set_xlabel('Number of Channels', fontsize=10)\n",
        "    axes[1, 2].set_ylabel('Frequency', fontsize=10)\n",
        "    axes[1, 2].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, 'audio_properties_analysis.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\n‚úÖ Audio properties plots saved!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Preprocessed Features Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if preprocessed files exist and analyze them\n",
        "print(\"=\"*60)\n",
        "print(\"PREPROCESSED FEATURES ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "preprocessed_files = {\n",
        "    'mel_spectrograms': 'mel_spectrograms.npy',\n",
        "    'audio_features': 'audio_features.npy',\n",
        "    'lyrics_embeddings': 'lyrics_embeddings.npy',\n",
        "    'hybrid_features': 'hybrid_features.npy',\n",
        "    'labels': 'labels.npy'\n",
        "}\n",
        "\n",
        "loaded_features = {}\n",
        "for name, filename in preprocessed_files.items():\n",
        "    filepath = os.path.join('.', filename)\n",
        "    if os.path.exists(filepath):\n",
        "        try:\n",
        "            loaded_features[name] = np.load(filepath)\n",
        "            print(f\"‚úÖ Loaded {name}: shape {loaded_features[name].shape}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è  Could not load {filename}: {e}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è  File not found: {filename}\")\n",
        "\n",
        "if len(loaded_features) == 0:\n",
        "    print(\"\\n‚ö†Ô∏è  No preprocessed features found. Run data_preprocessing.ipynb first.\")\n",
        "else:\n",
        "    print(f\"\\n‚úÖ Loaded {len(loaded_features)} preprocessed feature files\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze mel-spectrograms\n",
        "if 'mel_spectrograms' in loaded_features:\n",
        "    mel_specs = loaded_features['mel_spectrograms']\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"MEL-SPECTROGRAM ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Shape: {mel_specs.shape} (samples, n_mels, time_frames)\")\n",
        "    print(f\"Min value: {mel_specs.min():.4f}\")\n",
        "    print(f\"Max value: {mel_specs.max():.4f}\")\n",
        "    print(f\"Mean value: {mel_specs.mean():.4f}\")\n",
        "    print(f\"Std value: {mel_specs.std():.4f}\")\n",
        "    \n",
        "    # Visualize sample mel-spectrograms\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
        "    \n",
        "    # Sample 6 random spectrograms\n",
        "    if 'labels' in loaded_features:\n",
        "        labels = loaded_features['labels']\n",
        "        unique_labels = np.unique(labels)\n",
        "        \n",
        "        # Load genre mapping if available\n",
        "        genre_mapping = {}\n",
        "        if os.path.exists('genre_mapping.pkl'):\n",
        "            with open('genre_mapping.pkl', 'rb') as f:\n",
        "                mapping = pickle.load(f)\n",
        "                genre_mapping = mapping.get('label_to_genre', {})\n",
        "        \n",
        "        for idx, ax in enumerate(axes.flat):\n",
        "            # Sample from different genres if possible\n",
        "            if idx < len(unique_labels):\n",
        "                label = unique_labels[idx]\n",
        "                label_indices = np.where(labels == label)[0]\n",
        "                if len(label_indices) > 0:\n",
        "                    sample_idx = np.random.choice(label_indices)\n",
        "                    genre_name = genre_mapping.get(label, f'Label {label}')\n",
        "                else:\n",
        "                    sample_idx = np.random.randint(0, len(mel_specs))\n",
        "                    genre_name = 'Unknown'\n",
        "            else:\n",
        "                sample_idx = np.random.randint(0, len(mel_specs))\n",
        "                genre_name = 'Unknown'\n",
        "            \n",
        "            spec = mel_specs[sample_idx]\n",
        "            im = ax.imshow(spec, aspect='auto', origin='lower', cmap='viridis')\n",
        "            ax.set_title(f'Sample {sample_idx + 1}\\n{genre_name}', fontsize=10, fontweight='bold')\n",
        "            ax.set_xlabel('Time Frames', fontsize=9)\n",
        "            ax.set_ylabel('Mel Bands', fontsize=9)\n",
        "            plt.colorbar(im, ax=ax, fraction=0.046)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, 'sample_mel_spectrograms.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\n‚úÖ Sample mel-spectrograms plot saved!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze audio features\n",
        "if 'audio_features' in loaded_features:\n",
        "    audio_feat = loaded_features['audio_features']\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"AUDIO FEATURES ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Shape: {audio_feat.shape} (samples, features)\")\n",
        "    print(f\"Min value: {audio_feat.min():.4f}\")\n",
        "    print(f\"Max value: {audio_feat.max():.4f}\")\n",
        "    print(f\"Mean value: {audio_feat.mean():.4f}\")\n",
        "    print(f\"Std value: {audio_feat.std():.4f}\")\n",
        "    \n",
        "    # Feature statistics\n",
        "    feat_df = pd.DataFrame(audio_feat)\n",
        "    print(f\"\\nüìä Feature Statistics:\")\n",
        "    print(feat_df.describe())\n",
        "    \n",
        "    # Visualize feature distributions\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    \n",
        "    # Distribution of mean feature values\n",
        "    mean_features = feat_df.mean(axis=0)\n",
        "    axes[0, 0].hist(mean_features, bins=30, color='steelblue', edgecolor='black', alpha=0.7)\n",
        "    axes[0, 0].set_title('Distribution of Mean Feature Values', fontsize=12, fontweight='bold')\n",
        "    axes[0, 0].set_xlabel('Mean Feature Value', fontsize=10)\n",
        "    axes[0, 0].set_ylabel('Frequency', fontsize=10)\n",
        "    axes[0, 0].grid(alpha=0.3)\n",
        "    \n",
        "    # Distribution of std feature values\n",
        "    std_features = feat_df.std(axis=0)\n",
        "    axes[0, 1].hist(std_features, bins=30, color='coral', edgecolor='black', alpha=0.7)\n",
        "    axes[0, 1].set_title('Distribution of Std Feature Values', fontsize=12, fontweight='bold')\n",
        "    axes[0, 1].set_xlabel('Std Feature Value', fontsize=10)\n",
        "    axes[0, 1].set_ylabel('Frequency', fontsize=10)\n",
        "    axes[0, 1].grid(alpha=0.3)\n",
        "    \n",
        "    # Correlation matrix (sample features if too many)\n",
        "    if audio_feat.shape[1] <= 50:\n",
        "        corr_matrix = np.corrcoef(audio_feat.T)\n",
        "        im = axes[1, 0].imshow(corr_matrix, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\n",
        "        axes[1, 0].set_title('Feature Correlation Matrix', fontsize=12, fontweight='bold')\n",
        "        plt.colorbar(im, ax=axes[1, 0])\n",
        "    else:\n",
        "        # Sample 20 features for correlation\n",
        "        sample_indices = np.random.choice(audio_feat.shape[1], 20, replace=False)\n",
        "        corr_matrix = np.corrcoef(audio_feat[:, sample_indices].T)\n",
        "        im = axes[1, 0].imshow(corr_matrix, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\n",
        "        axes[1, 0].set_title('Feature Correlation Matrix (20 sampled features)', fontsize=12, fontweight='bold')\n",
        "        plt.colorbar(im, ax=axes[1, 0])\n",
        "    \n",
        "    # Feature variance\n",
        "    feature_variance = feat_df.var(axis=0)\n",
        "    top_var_indices = feature_variance.nlargest(20).index\n",
        "    axes[1, 1].barh(range(len(top_var_indices)), feature_variance[top_var_indices], \n",
        "                    color='mediumseagreen', edgecolor='black', alpha=0.7)\n",
        "    axes[1, 1].set_yticks(range(len(top_var_indices)))\n",
        "    axes[1, 1].set_yticklabels([f'Feature {i}' for i in top_var_indices])\n",
        "    axes[1, 1].set_title('Top 20 Features by Variance', fontsize=12, fontweight='bold')\n",
        "    axes[1, 1].set_xlabel('Variance', fontsize=10)\n",
        "    axes[1, 1].grid(axis='x', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, 'audio_features_analysis.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\n‚úÖ Audio features analysis plots saved!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze labels distribution\n",
        "if 'labels' in loaded_features:\n",
        "    labels = loaded_features['labels']\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"LABELS ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "    print(f\"Total samples: {len(labels)}\")\n",
        "    print(f\"Number of unique labels: {len(unique_labels)}\")\n",
        "    print(f\"\\nLabel distribution:\")\n",
        "    \n",
        "    # Load genre mapping if available\n",
        "    genre_mapping = {}\n",
        "    if os.path.exists('genre_mapping.pkl'):\n",
        "        with open('genre_mapping.pkl', 'rb') as f:\n",
        "            mapping = pickle.load(f)\n",
        "            genre_mapping = mapping.get('label_to_genre', {})\n",
        "    \n",
        "    for label, count in zip(unique_labels, counts):\n",
        "        genre_name = genre_mapping.get(label, f'Label {label}')\n",
        "        percentage = (count / len(labels)) * 100\n",
        "        print(f\"   {genre_name} (label {label}): {count} ({percentage:.2f}%)\")\n",
        "    \n",
        "    # Visualize label distribution\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "    \n",
        "    # Bar chart\n",
        "    genre_names = [genre_mapping.get(l, f'Label {l}') for l in unique_labels]\n",
        "    axes[0].bar(range(len(unique_labels)), counts, color=sns.color_palette(\"husl\", len(unique_labels)), \n",
        "                edgecolor='black', alpha=0.7)\n",
        "    axes[0].set_xticks(range(len(unique_labels)))\n",
        "    axes[0].set_xticklabels(genre_names, rotation=45, ha='right')\n",
        "    axes[0].set_title('Label Distribution (Bar Chart)', fontsize=12, fontweight='bold')\n",
        "    axes[0].set_xlabel('Genre', fontsize=10)\n",
        "    axes[0].set_ylabel('Count', fontsize=10)\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Add count labels\n",
        "    for i, v in enumerate(counts):\n",
        "        axes[0].text(i, v + max(counts)*0.01, str(v), ha='center', va='bottom', fontweight='bold', fontsize=8)\n",
        "    \n",
        "    # Pie chart\n",
        "    axes[1].pie(counts, labels=genre_names, autopct='%1.1f%%', startangle=90,\n",
        "                colors=sns.color_palette(\"husl\", len(unique_labels)))\n",
        "    axes[1].set_title('Label Distribution (Pie Chart)', fontsize=12, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, 'labels_distribution.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\n‚úÖ Labels distribution plot saved!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Data Quality Checks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data quality checks\n",
        "print(\"=\"*60)\n",
        "print(\"DATA QUALITY CHECKS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "quality_issues = []\n",
        "\n",
        "# Check metadata\n",
        "print(\"\\nüìã Metadata Quality Checks:\")\n",
        "print(f\"   Total entries: {len(metadata_df)}\")\n",
        "print(f\"   Missing values:\")\n",
        "for col in metadata_df.columns:\n",
        "    missing = metadata_df[col].isnull().sum()\n",
        "    if missing > 0:\n",
        "        percentage = (missing / len(metadata_df)) * 100\n",
        "        print(f\"      - {col}: {missing} ({percentage:.2f}%)\")\n",
        "        quality_issues.append(f\"Missing values in {col}: {missing} ({percentage:.2f}%)\")\n",
        "\n",
        "# Check for duplicate IDs\n",
        "duplicate_ids = metadata_df['ID'].duplicated().sum()\n",
        "if duplicate_ids > 0:\n",
        "    print(f\"   ‚ö†Ô∏è  Duplicate IDs: {duplicate_ids}\")\n",
        "    quality_issues.append(f\"Duplicate IDs: {duplicate_ids}\")\n",
        "else:\n",
        "    print(f\"   ‚úÖ No duplicate IDs\")\n",
        "\n",
        "# Check audio files\n",
        "print(\"\\nüìÅ Audio Files Quality Checks:\")\n",
        "total_expected = sum(bangla_file_counts.values()) + sum(english_file_counts.values())\n",
        "print(f\"   Expected total files: {total_expected}\")\n",
        "\n",
        "# Check for missing audio files (sample check)\n",
        "missing_files = 0\n",
        "for genre in list(bangla_genres[:2]):  # Check first 2 genres\n",
        "    genre_path = os.path.join(BANGLA_DATASET_DIR, genre)\n",
        "    genre_metadata = metadata_df[(metadata_df['language'] == 'bn') & (metadata_df['genre'] == genre)]\n",
        "    if len(genre_metadata) > 0:\n",
        "        for _, row in genre_metadata.head(10).iterrows():  # Check first 10\n",
        "            file_path = os.path.join(genre_path, f\"{row['ID']}.wav\")\n",
        "            if not os.path.exists(file_path):\n",
        "                missing_files += 1\n",
        "\n",
        "if missing_files > 0:\n",
        "    print(f\"   ‚ö†Ô∏è  Sample check found {missing_files} missing audio files\")\n",
        "    quality_issues.append(f\"Missing audio files (sample): {missing_files}\")\n",
        "else:\n",
        "    print(f\"   ‚úÖ Sample check: No missing audio files found\")\n",
        "\n",
        "# Check preprocessed features consistency\n",
        "if len(loaded_features) > 1:\n",
        "    print(\"\\nüìä Preprocessed Features Consistency:\")\n",
        "    feature_shapes = {name: feat.shape[0] for name, feat in loaded_features.items() if len(feat.shape) > 0}\n",
        "    if len(set(feature_shapes.values())) == 1:\n",
        "        print(f\"   ‚úÖ All features have consistent sample count: {list(feature_shapes.values())[0]}\")\n",
        "    else:\n",
        "        print(f\"   ‚ö†Ô∏è  Inconsistent sample counts:\")\n",
        "        for name, count in feature_shapes.items():\n",
        "            print(f\"      - {name}: {count}\")\n",
        "        quality_issues.append(\"Inconsistent feature sample counts\")\n",
        "\n",
        "# Summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"QUALITY SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "if len(quality_issues) == 0:\n",
        "    print(\"‚úÖ No major quality issues detected!\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Found {len(quality_issues)} potential issues:\")\n",
        "    for issue in quality_issues:\n",
        "        print(f\"   - {issue}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Summary and Conclusions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate summary report\n",
        "print(\"=\"*60)\n",
        "print(\"EDA SUMMARY REPORT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nüìä DATASET OVERVIEW:\")\n",
        "print(f\"   - Total audio files: {total_files}\")\n",
        "print(f\"   - Languages: Bangla ({sum(bangla_file_counts.values())} files), English ({sum(english_file_counts.values())} files)\")\n",
        "print(f\"   - Total genres: {total_genres}\")\n",
        "print(f\"   - Metadata entries: {len(metadata_df)}\")\n",
        "\n",
        "print(\"\\nüìã METADATA:\")\n",
        "print(f\"   - Languages: {', '.join(metadata_df['language'].unique())}\")\n",
        "print(f\"   - Genres: {len(metadata_df['genre'].unique())} unique genres\")\n",
        "if 'bn' in metadata_df['language'].values:\n",
        "    bangla_with_lyrics = metadata_df[(metadata_df['language'] == 'bn') & \n",
        "                                     (metadata_df['lyrics'].fillna('').str.len() > 0)]\n",
        "    print(f\"   - Bangla entries with lyrics: {len(bangla_with_lyrics)}\")\n",
        "\n",
        "print(\"\\nüìÅ PREPROCESSED FEATURES:\")\n",
        "if len(loaded_features) > 0:\n",
        "    for name, feat in loaded_features.items():\n",
        "        print(f\"   - {name}: {feat.shape}\")\n",
        "else:\n",
        "    print(\"   - No preprocessed features found\")\n",
        "\n",
        "print(\"\\n‚úÖ All analysis plots have been saved to the results directory!\")\n",
        "print(f\"   Results directory: {RESULTS_DIR}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EDA COMPLETE!\")\n",
        "print(\"=\"*60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
