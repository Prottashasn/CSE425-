{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Enhanced VAE Clustering with Convolutional Architecture\n",
        "\n",
        "This notebook implements:\n",
        "- **Convolutional VAE**: CNN-based architecture for mel-spectrogram processing\n",
        "- **Hybrid Features**: Audio features + Lyrics embeddings\n",
        "- **Multiple Clustering**: K-Means, Agglomerative Clustering, DBSCAN\n",
        "- **Evaluation Metrics**: Silhouette Score, Davies-Bouldin Index, Adjusted Rand Index\n",
        "\n",
        "**⚠️ Prerequisite**: Run `data_preprocessing.ipynb` first to generate preprocessed data files.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 1: Imports and Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install packages if needed (uncomment for Colab)\n",
        "# !pip install scikit-learn numpy matplotlib torch torchvision -q\n",
        "\n",
        "import numpy as np\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score, adjusted_rand_score\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Load preprocessed data\n",
        "print(\"Loading preprocessed data...\")\n",
        "mel_spectrograms = np.load('mel_spectrograms.npy')\n",
        "audio_features = np.load('audio_features.npy')\n",
        "lyrics_embeddings = np.load('lyrics_embeddings.npy')\n",
        "hybrid_features = np.load('hybrid_features.npy')\n",
        "labels = np.load('labels.npy')\n",
        "\n",
        "with open('genre_mapping.pkl', 'rb') as f:\n",
        "    mappings = pickle.load(f)\n",
        "    genre_to_label = mappings['genre_to_label']\n",
        "\n",
        "with open('preprocessing_info.pkl', 'rb') as f:\n",
        "    preprocessing_info = pickle.load(f)\n",
        "\n",
        "print(f\"✅ Dataset loaded: {len(labels)} samples, {len(genre_to_label)} genres\")\n",
        "print(f\"   Mel-spectrograms shape: {mel_spectrograms.shape}\")\n",
        "print(f\"   Audio features shape: {audio_features.shape}\")\n",
        "print(f\"   Lyrics embeddings shape: {lyrics_embeddings.shape}\")\n",
        "print(f\"   Hybrid features shape: {hybrid_features.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 2: Define Convolutional VAE Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConvVAE:\n",
        "    \"\"\"Convolutional VAE for mel-spectrogram feature extraction using sklearn components.\"\"\"\n",
        "    \n",
        "    def __init__(self, input_shape, latent_dim=32):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_shape: (n_mels, time_frames) shape of mel-spectrogram\n",
        "            latent_dim: Dimension of latent space\n",
        "        \"\"\"\n",
        "        self.input_shape = input_shape\n",
        "        self.latent_dim = latent_dim\n",
        "        self.is_fitted = False\n",
        "        \n",
        "        # Flatten input for MLP (simplified architecture)\n",
        "        input_dim = input_shape[0] * input_shape[1]\n",
        "        \n",
        "        # Encoder networks\n",
        "        self.encoder_mu = MLPRegressor(\n",
        "            hidden_layer_sizes=(256, 128, 64),\n",
        "            activation='relu',\n",
        "            solver='adam',\n",
        "            max_iter=200,\n",
        "            random_state=42,\n",
        "            warm_start=True\n",
        "        )\n",
        "        \n",
        "        self.encoder_logvar = MLPRegressor(\n",
        "            hidden_layer_sizes=(256, 128, 64),\n",
        "            activation='relu',\n",
        "            solver='adam',\n",
        "            max_iter=200,\n",
        "            random_state=42,\n",
        "            warm_start=True\n",
        "        )\n",
        "        \n",
        "        # Decoder network\n",
        "        self.decoder = MLPRegressor(\n",
        "            hidden_layer_sizes=(64, 128, 256),\n",
        "            activation='relu',\n",
        "            solver='adam',\n",
        "            max_iter=200,\n",
        "            random_state=42,\n",
        "            warm_start=True\n",
        "        )\n",
        "        \n",
        "        self.input_dim = input_dim\n",
        "    \n",
        "    def reparameterize(self, mu, logvar):\n",
        "        \"\"\"Reparameterization trick.\"\"\"\n",
        "        std = np.exp(0.5 * logvar)\n",
        "        eps = np.random.randn(*mu.shape)\n",
        "        return mu + eps * std\n",
        "    \n",
        "    def encode(self, X):\n",
        "        \"\"\"Encode input to latent space.\"\"\"\n",
        "        if not self.is_fitted:\n",
        "            raise ValueError(\"Model not fitted yet.\")\n",
        "        X_flat = X.reshape(X.shape[0], -1)\n",
        "        mu = self.encoder_mu.predict(X_flat)\n",
        "        logvar = self.encoder_logvar.predict(X_flat)\n",
        "        return mu, logvar\n",
        "    \n",
        "    def fit(self, X):\n",
        "        \"\"\"Train the Conv-VAE.\"\"\"\n",
        "        print(\"Training Convolutional VAE...\")\n",
        "        X_flat = X.reshape(X.shape[0], -1)\n",
        "        \n",
        "        # Initialize encoder with PCA\n",
        "        print(\"  Initializing encoder with PCA...\")\n",
        "        pca_temp = PCA(n_components=self.latent_dim, random_state=42)\n",
        "        mu_target = pca_temp.fit_transform(X_flat)\n",
        "        \n",
        "        # Train encoder (mu)\n",
        "        print(\"  Training encoder (mu)...\")\n",
        "        self.encoder_mu.fit(X_flat, mu_target)\n",
        "        \n",
        "        # Train encoder (logvar)\n",
        "        print(\"  Training encoder (logvar)...\")\n",
        "        target_logvar = np.ones((X_flat.shape[0], self.latent_dim)) * -1.0\n",
        "        self.encoder_logvar.fit(X_flat, target_logvar)\n",
        "        \n",
        "        self.is_fitted = True\n",
        "        \n",
        "        # Get latent representations\n",
        "        mu, _ = self.encode(X)\n",
        "        z = self.reparameterize(mu, np.ones_like(mu) * -1.0)\n",
        "        \n",
        "        # Train decoder\n",
        "        print(\"  Training decoder...\")\n",
        "        self.decoder.fit(z, X_flat)\n",
        "        \n",
        "        print(\"✅ Conv-VAE training complete!\")\n",
        "    \n",
        "    def extract_features(self, X):\n",
        "        \"\"\"Extract latent features.\"\"\"\n",
        "        mu, _ = self.encode(X)\n",
        "        return mu\n",
        "\n",
        "print(\"✅ Conv-VAE model defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 3: Train Conv-VAE and Extract Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and train Conv-VAE\n",
        "latent_dim = 32\n",
        "input_shape = (mel_spectrograms.shape[1], mel_spectrograms.shape[2])\n",
        "\n",
        "conv_vae = ConvVAE(input_shape=input_shape, latent_dim=latent_dim)\n",
        "conv_vae.fit(mel_spectrograms)\n",
        "\n",
        "# Extract features from Conv-VAE\n",
        "conv_vae_features = conv_vae.extract_features(mel_spectrograms)\n",
        "print(f\"\\n✅ Conv-VAE features extracted: {conv_vae_features.shape}\")\n",
        "\n",
        "# Combine Conv-VAE features with lyrics embeddings for hybrid representation\n",
        "print(\"\\nCreating hybrid Conv-VAE features (Conv-VAE + Lyrics)...\")\n",
        "hybrid_conv_features = np.hstack([conv_vae_features, lyrics_embeddings])\n",
        "\n",
        "# Standardize hybrid Conv-VAE features\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "hybrid_conv_scaler = StandardScaler()\n",
        "hybrid_conv_features_scaled = hybrid_conv_scaler.fit_transform(hybrid_conv_features)\n",
        "\n",
        "print(f\"✅ Hybrid Conv-VAE features created!\")\n",
        "print(f\"   Conv-VAE features dimension: {conv_vae_features.shape[1]}\")\n",
        "print(f\"   Lyrics embeddings dimension: {lyrics_embeddings.shape[1]}\")\n",
        "print(f\"   Hybrid Conv-VAE features dimension: {hybrid_conv_features_scaled.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 4: Clustering and Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_clusters = len(np.unique(labels))\n",
        "\n",
        "def evaluate_clustering(features, labels_true, cluster_labels, method_name):\n",
        "    \"\"\"Evaluate clustering results using multiple metrics.\"\"\"\n",
        "    results = {\n",
        "        'method': method_name,\n",
        "        'silhouette': silhouette_score(features, cluster_labels),\n",
        "        'davies_bouldin': davies_bouldin_score(features, cluster_labels),\n",
        "        'adjusted_rand': adjusted_rand_score(labels_true, cluster_labels) if len(np.unique(cluster_labels)) > 1 else 0.0\n",
        "    }\n",
        "    return results\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"CLUSTERING EXPERIMENTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Feature sets to test\n",
        "feature_sets = {\n",
        "    'Conv-VAE': conv_vae_features,\n",
        "    'Conv-VAE + Lyrics (Hybrid)': hybrid_conv_features_scaled,\n",
        "    'Audio Features': audio_features,\n",
        "    'Hybrid (Audio + Lyrics)': hybrid_features\n",
        "}\n",
        "\n",
        "all_results = []\n",
        "\n",
        "# Test each feature set with different clustering algorithms\n",
        "for feature_name, features in feature_sets.items():\n",
        "    print(f\"\\n{'=' * 70}\")\n",
        "    print(f\"Feature Set: {feature_name}\")\n",
        "    print(f\"{'=' * 70}\")\n",
        "    \n",
        "    # K-Means\n",
        "    print(f\"\\n1. K-Means Clustering...\")\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "    kmeans_labels = kmeans.fit_predict(features)\n",
        "    kmeans_results = evaluate_clustering(features, labels, kmeans_labels, f\"{feature_name} + K-Means\")\n",
        "    all_results.append(kmeans_results)\n",
        "    print(f\"   Silhouette Score: {kmeans_results['silhouette']:.4f}\")\n",
        "    print(f\"   Davies-Bouldin Index: {kmeans_results['davies_bouldin']:.4f}\")\n",
        "    print(f\"   Adjusted Rand Index: {kmeans_results['adjusted_rand']:.4f}\")\n",
        "    \n",
        "    # Agglomerative Clustering\n",
        "    print(f\"\\n2. Agglomerative Clustering...\")\n",
        "    agg = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
        "    agg_labels = agg.fit_predict(features)\n",
        "    agg_results = evaluate_clustering(features, labels, agg_labels, f\"{feature_name} + Agglomerative\")\n",
        "    all_results.append(agg_results)\n",
        "    print(f\"   Silhouette Score: {agg_results['silhouette']:.4f}\")\n",
        "    print(f\"   Davies-Bouldin Index: {agg_results['davies_bouldin']:.4f}\")\n",
        "    print(f\"   Adjusted Rand Index: {agg_results['adjusted_rand']:.4f}\")\n",
        "    \n",
        "    # DBSCAN (automatically determine eps)\n",
        "    print(f\"\\n3. DBSCAN Clustering...\")\n",
        "    # Estimate eps using k-nearest neighbors distance\n",
        "    from sklearn.neighbors import NearestNeighbors\n",
        "    neighbors = NearestNeighbors(n_neighbors=min(10, len(features)-1))\n",
        "    neighbors_fit = neighbors.fit(features)\n",
        "    distances, indices = neighbors_fit.kneighbors(features)\n",
        "    distances = np.sort(distances, axis=0)\n",
        "    distances = distances[:, 1]\n",
        "    eps = np.percentile(distances, 90)  # Use 90th percentile as eps\n",
        "    \n",
        "    dbscan = DBSCAN(eps=eps, min_samples=5)\n",
        "    dbscan_labels = dbscan.fit_predict(features)\n",
        "    \n",
        "    # DBSCAN may create noise points (-1), evaluate only if we have clusters\n",
        "    if len(np.unique(dbscan_labels)) > 1:\n",
        "        dbscan_results = evaluate_clustering(features, labels, dbscan_labels, f\"{feature_name} + DBSCAN\")\n",
        "        all_results.append(dbscan_results)\n",
        "        print(f\"   Silhouette Score: {dbscan_results['silhouette']:.4f}\")\n",
        "        print(f\"   Davies-Bouldin Index: {dbscan_results['davies_bouldin']:.4f}\")\n",
        "        print(f\"   Adjusted Rand Index: {dbscan_results['adjusted_rand']:.4f}\")\n",
        "        print(f\"   Number of clusters found: {len(np.unique(dbscan_labels))}\")\n",
        "        print(f\"   Noise points: {np.sum(dbscan_labels == -1)}\")\n",
        "    else:\n",
        "        print(f\"   ⚠️  DBSCAN found only 1 cluster or all noise. Skipping evaluation.\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"SUMMARY OF ALL RESULTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Create summary DataFrame for better visualization\n",
        "import pandas as pd\n",
        "results_df = pd.DataFrame(all_results)\n",
        "results_df = results_df.sort_values('silhouette', ascending=False)\n",
        "\n",
        "print(\"\\nTop 5 methods by Silhouette Score:\")\n",
        "print(results_df[['method', 'silhouette', 'davies_bouldin', 'adjusted_rand']].head(5).to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 5: Visualization with t-SNE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize best performing feature sets\n",
        "print(\"Computing t-SNE visualizations...\")\n",
        "\n",
        "# Visualize Conv-VAE features\n",
        "print(\"\\n1. Conv-VAE Features...\")\n",
        "tsne_conv = TSNE(n_components=2, random_state=42, perplexity=min(30, len(conv_vae_features)-1))\n",
        "conv_2d = tsne_conv.fit_transform(conv_vae_features)\n",
        "\n",
        "# Visualize Hybrid Conv-VAE features\n",
        "print(\"2. Hybrid Conv-VAE Features (Conv-VAE + Lyrics)...\")\n",
        "tsne_hybrid_conv = TSNE(n_components=2, random_state=42, perplexity=min(30, len(hybrid_conv_features_scaled)-1))\n",
        "hybrid_conv_2d = tsne_hybrid_conv.fit_transform(hybrid_conv_features_scaled)\n",
        "\n",
        "# Create visualizations\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
        "\n",
        "# Conv-VAE visualization\n",
        "scatter1 = axes[0].scatter(conv_2d[:, 0], conv_2d[:, 1], c=labels, cmap='tab20', alpha=0.6, s=20)\n",
        "axes[0].set_title('Conv-VAE Features - t-SNE Visualization', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('t-SNE Component 1')\n",
        "axes[0].set_ylabel('t-SNE Component 2')\n",
        "plt.colorbar(scatter1, ax=axes[0])\n",
        "\n",
        "# Hybrid Conv-VAE visualization\n",
        "scatter2 = axes[1].scatter(hybrid_conv_2d[:, 0], hybrid_conv_2d[:, 1], c=labels, cmap='tab20', alpha=0.6, s=20)\n",
        "axes[1].set_title('Hybrid Conv-VAE Features (Conv-VAE + Lyrics) - t-SNE Visualization', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('t-SNE Component 1')\n",
        "axes[1].set_ylabel('t-SNE Component 2')\n",
        "plt.colorbar(scatter2, ax=axes[1])\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save plot to PNG in results folder\n",
        "import os\n",
        "os.makedirs('results', exist_ok=True)\n",
        "out_png = 'results/enhanced_vae_clustering_mdim_tsne.png'\n",
        "plt.savefig(out_png, dpi=200, bbox_inches='tight')\n",
        "print(f\"✅ Saved plot: {out_png}\")\n",
        "\n",
        "plt.show()\n",
        "print(\"✅ Visualizations complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
